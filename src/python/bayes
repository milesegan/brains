#!/usr/bin/env python
# simple bayesian classifier in python

from __future__ import division
import random
import os,sys

class BayesClassifier(object):
    def __init__(s):
        s.pc = {}
        s.pf = {}
        s.pfc = {}
        s.count = 0.0

    def train(s, klass, features):
        s.pc.setdefault(klass, 0)
        s.pc[klass] += 1
        for feat, val in features:
            s.pf.setdefault((feat, val), 0)
            s.pf[(feat, val)] += 1
            s.pfc.setdefault((feat, val, klass), 0)
            s.pfc[(feat, val, klass)] += 1
        s.count += 1

    def classify(s, features):
        ranked = []
        for c in s.pc.keys():
            p = 1
            for f in features:
                pfckey = f + (c,)
                if s.pfc.has_key(pfckey) and s.pf.has_key(f) and s.pc.has_key(c):
                    p *= s.pfc.get(pfckey) * s.pf[f] / (s.pc[c] * s.count)
                else:
                    p *= 0.01 / s.count # TODO: adjust this
            ranked.append((p, c))
        ranked.sort()
        return ranked[-1][1]

def main():
    raw = sys.stdin.read().strip().split("\n")
    features = raw[0].split(",")[1:]
    data = [i.split(",") for i in raw[1:]]
    data = [zip(features, d) for d in data]

    random.shuffle(data)
    cutoff = int(len(data) / 4)
    test = data[0:cutoff]
    train = data[cutoff:]

    bc = BayesClassifier()
    for d in train:
        klass = d[0][1]
        feat = d[1:]
        bc.train(klass, feat)

    correct = 0
    for d in test:
        klass = d[0][1]
        feat = d[1:]
        predict = bc.classify(feat)
        if klass == predict:
            correct += 1
        print("%s => %s" % (klass, predict))
    print(correct / len(test))

main()
