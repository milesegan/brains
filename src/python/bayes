#!/usr/bin/env python
# simple bayesian classifier in python

from __future__ import division
import random
import os, re, sys

class BayesClassifier(object):
    def __init__(s):
        s.pc = {}
        s.pf = {}
        s.pfc = {}
        s.count = 0.0

    def train(s, klass, features):
        s.pc.setdefault(klass, 0)
        s.pc[klass] += 1
        for feat, val in features:
            s.pf.setdefault((feat, val), 0)
            s.pf[(feat, val)] += 1
            s.pfc.setdefault((feat, val, klass), 0)
            s.pfc[(feat, val, klass)] += 1
        s.count += 1

    def classify(s, features):
        ranked = []
        for c in s.pc.keys():
            p = 1
            for f in features:
                pfckey = f + (c,)
                if s.pfc.has_key(pfckey):
                    p *= s.pfc.get(pfckey) / s.count
                else:
                    p *= 0.01 / s.count # TODO: adjust this
            ranked.append((p * s.pc.get(c, 0.0), c))
        ranked.sort()
        return ranked[-1][1]

def main():
    raw = sys.stdin.read().strip().split("\n")
    data = [re.sub(r"#.*", "", i) for i in raw]
    data = [i.split(",") for i in data if len(i) > 0]
    features = data[0][1:]
    data = [zip(features, d) for d in data[1:]]

    random.shuffle(data)
    cutoff = int(len(data) / 4)
    test = data[0:cutoff]
    train = data[cutoff:]

    bc = BayesClassifier()
    for d in train:
        klass = d[0][1]
        feat = d[1:]
        bc.train(klass, feat)

    correct = 0
    for d in test:
        klass = d[0][1]
        feat = d[1:]
        predict = bc.classify(feat)
        if klass == predict:
            correct += 1
        print("%s => %s" % (klass, predict))
    print(correct / len(test))

main()
